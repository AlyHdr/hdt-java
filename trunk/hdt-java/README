HDT Library, Java Implementation. http://www.rdfhdt.org

Overview
=================

HDT-lib is a Java Library that implements the W3C Submission (http://www.w3.org/Submission/2011/03/) of the RDF HDT (Header-Dictionary-Triples) binary format for publishing and exchanging RDF data at large scale. Its compact representation allows storing RDF in fewer space, providing at the same time direct access to the stored information. This is achieved by depicting the RDF graph in terms of three main components: Header, Dictionary and Triples. The Header includes extensible metadata required to describe the RDF data set and details of its internals. The Dictionary organizes the vocabulary of strings present in the RDF graph by assigning numerical IDs to each different string. The Triples component comprises the internal structure of the RDF graph in a compressed form.

It provides two components:
- Java Library: Provides an API to use HDT files programmatically. It allows creating HDT files from RDF and converting HDT files back to RDF. It also provides a Search interface to find triples that match a specific triple pattern.
- Command line tools. Allow to convert between RDF and HDT, and also perform searches against HDT files.

Compiling
=================

The source package contains an Ant buildfile "build.xml". 

Just run 'ant' to compile or 'ant jar' to generate a jar package.
			
Dependencies for searching:
The HDT library itself does not have any dependency to load and search HDT files, you just need to include the generated jar. 

Dependencies for converting:
The commandline tools use JCommander for parsing the arguments.
For parsing RDF files (in NTriples, Turtle, N3, RDF-XML...) you will need Jena RIOT.
If you need to convert very big RDF Files, you can use BerkeleyDB, KyotoCabinet or JDBM to save intermediate data on disk. 

Command line tools
=================

The tool provides three main command line tools:

** The tool rdf2hdt converts an RDF file to HDT format. The format of the input file will be NTriples by default, although it can be set by using the "-rdftype" flag. 

$ Usage: ./rdf2hdt.sh [options] <RDF file> <HDT file>
  Options:
    -base      Base URI for the dataset
    -config    Conversion config file
    -options   HDT Conversion options
    -rdftype   Type of RDF Input (ntriples, n3, rdfxml)


** The tool hdt2rdf converts an HDT file back to RDF in NTriples format.

$ hdt2rdf [options] <HDT input file> <RDF output file> 
	-h			This help

** The tool hdtSearch allows to search triple patterns against an HDT file. For example, to list all patterns, one can use the "? ? ?" query. To search all information about <myns:subject1> one can use "<myns:subject1> ? ?"

$ hdtSearch [options] <hdtfile> 
	-h			This help
	-q	<query>	Launch query and exit.
	-o	<output>	Save query output to file.



Tool Usage example
=================

After installation, run:

$ tools/rdf2hdt data/test.nt data/test.hdt
# This creates the HDT representation

$ tools/hdt2rdf data/test.hdt data/test.hdtexport.nt
# This converts back the HDT to RDF.

$ tools/hdtSearch data/test.hdt

>> ? ? ?
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri4>
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri5>
<http://example.org/uri1> <http://example.org/predicate1> "literal1"
<http://example.org/uri1> <http://example.org/predicate1> "literalA"
<http://example.org/uri1> <http://example.org/predicate1> "literalB"
<http://example.org/uri1> <http://example.org/predicate1> "literalC"
<http://example.org/uri1> <http://example.org/predicate2> <http://example.org/uri3>
<http://example.org/uri1> <http://example.org/predicate2> <http://example.org/uriA3>
<http://example.org/uri2> <http://example.org/predicate1> "literal1"
9 results shown.

>> <http://example.org/uri3> ? ?
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri4>
<http://example.org/uri3> <http://example.org/predicate3> <http://example.org/uri5>
2 results shown.

>> exit


USING THE LIBRARY
=================

Here we show how to use the library programmatically from java. This code can also be found under the examples directory.

// Generate an HDT File from RDF (examples/ExampleGenerate.java)
public static void main(String[] args) throws Exception {
	// Configuration variables
	String baseURI = "http://example.com/mydataset";
	String rdfInput = "/path/to/dataset.nt";
	String inputType = "ntriples";
	String hdtOutput = "/path/to/dataset.hdt";
	
	// Create HDT from RDF file
	HDTSpecification spec = new HDTSpecification();
	HDT hdt = HDTFactory.createHDTFromRDF(spec, rdfInput, baseURI, RDFNotation.parse(inputType), null);
	
	// Save generated HDT to a file
	hdt.saveToHDT(hdtOutput, null);
}

// Load an HDT and perform a search.
public static void main(String[] args) throws Exception {
	// Load HDT file
	QueryableHDT hdt = HDTFactory.createQueryableHDT();
	hdt.loadFromHDT("data/example.hdt", null);

	// Recommended: Generate index to speed up ?P? ?PO and ??O queries.
	hdt.loadOrCreateIndex(null);

	// Search pattern: Empty string means "any"
	IteratorTripleString it = hdt.search("", "", "");
	while(it.hasNext()) {
		TripleString ts = it.next();
		System.out.println(ts);
	}
}
